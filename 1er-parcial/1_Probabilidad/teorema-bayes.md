# Gu√≠a: Teorema de Bayes

## Introducci√≥n

El **Teorema de Bayes** es una herramienta fundamental en probabilidad que nos permite "invertir" probabilidades condicionales. Es especialmente √∫til cuando conocemos la probabilidad de un efecto dada una causa, pero necesitamos la probabilidad de la causa dado el efecto.

## Definici√≥n Fundamental

### ¬øQu√© es el Teorema de Bayes?

El **Teorema de Bayes** nos permite calcular P(A|B) cuando conocemos P(B|A), P(A) y P(B).

### F√≥rmula del Teorema de Bayes

**P(A|B) = [P(B|A) √ó P(A)] / P(B)**

### Componentes de la F√≥rmula:

- **P(A|B)**: Probabilidad **a posteriori** (lo que queremos encontrar)
- **P(B|A)**: Probabilidad de la evidencia dado el evento (verosimilitud)
- **P(A)**: Probabilidad **a priori** del evento
- **P(B)**: Probabilidad total de la evidencia (denominador normalizador)

### F√≥rmula Extendida con Probabilidad Total:

**P(A|B) = [P(B|A) √ó P(A)] / [Œ£ P(B|A·µ¢) √ó P(A·µ¢)]**

## Identificaci√≥n Sem√°ntica: Cu√°ndo Usar Bayes

### ‚úÖ Palabras clave que indican uso de Bayes:

- **"Si [resultado], ¬øcu√°l es la probabilidad de que [causa]?"**
  - Ejemplo: "Si el televisor es defectuoso, ¬øcu√°l es la probabilidad de que sea marca 1?"

- **"Dado que [efecto ocurri√≥], ¬øprobabilidad de [causa espec√≠fica]?"**
  - Ejemplo: "Dado que la prueba es positiva, ¬øprobabilidad de tener la enfermedad?"

- **"¬øDe d√≥nde proviene m√°s probablemente [el resultado]?"**
  - Ejemplo: "¬øDe qu√© m√°quina proviene m√°s probablemente el producto defectuoso?"

- **"¬øCu√°l es la causa m√°s probable de [el efecto]?"**
  - Ejemplo: "¬øCu√°l es la marca m√°s probable del televisor defectuoso?"

### ‚ùå NO es Bayes cuando:

- **Preguntan por P(B|A) directamente** (ya lo conoces)
- **Preguntan por probabilidad total** (usa f√≥rmula de probabilidad total)
- **No hay "inversi√≥n" de la condicional**

## Ejemplo 1: Televisores Defectuosos

### Enunciado:
*"Una empresa vende televisores de 3 marcas: 50% marca 1, 30% marca 2, 20% marca 3. Se sabe que el 25% de los televisores de marca 1 necesita reparaci√≥n, el 20% de marca 2 y el 10% de marca 3. Si un cliente vuelve con un televisor defectuoso, ¬øcu√°l es la probabilidad de que sea de marca 1?"*

### An√°lisis Sem√°ntico:
- **"Si un cliente vuelve con un televisor defectuoso"** ‚Üí Tenemos la evidencia (efecto)
- **"¬øcu√°l es la probabilidad de que sea de marca 1?"** ‚Üí Buscamos la causa
- **Estructura**: "Si [efecto], ¬øprobabilidad de [causa]?" ‚Üí **BAYES**

### Datos del Problema:
- P(A‚ÇÅ) = 0.50, P(A‚ÇÇ) = 0.30, P(A‚ÇÉ) = 0.20 (probabilidades a priori)
- P(D|A‚ÇÅ) = 0.25, P(D|A‚ÇÇ) = 0.20, P(D|A‚ÇÉ) = 0.10 (verosimilitudes)

### Soluci√≥n Paso a Paso:

**Paso 1: Calcular P(D) - Probabilidad total**
P(D) = P(D|A‚ÇÅ)√óP(A‚ÇÅ) + P(D|A‚ÇÇ)√óP(A‚ÇÇ) + P(D|A‚ÇÉ)√óP(A‚ÇÉ)
P(D) = 0.25√ó0.50 + 0.20√ó0.30 + 0.10√ó0.20 = 0.125 + 0.06 + 0.02 = 0.205

**Paso 2: Aplicar Bayes**
P(A‚ÇÅ|D) = [P(D|A‚ÇÅ) √ó P(A‚ÇÅ)] / P(D) = [0.25 √ó 0.50] / 0.205 = 0.125 / 0.205 ‚âà 0.610

### Visualizaci√≥n con 10,000 Televisores:

**üìä Distribuci√≥n por Marca:**
- **Marca 1**: 10,000 √ó 0.50 = **5,000 televisores**
- **Marca 2**: 10,000 √ó 0.30 = **3,000 televisores**
- **Marca 3**: 10,000 √ó 0.20 = **2,000 televisores**

**üîß Televisores Defectuosos:**
- **Marca 1 defectuosos**: 5,000 √ó 0.25 = **1,250 televisores**
- **Marca 2 defectuosos**: 3,000 √ó 0.20 = **600 televisores**
- **Marca 3 defectuosos**: 2,000 √ó 0.10 = **200 televisores**
- **Total defectuosos**: 1,250 + 600 + 200 = **2,050 televisores**

### üìä Matriz de Confusi√≥n para Marca 1:

| | **Defectuoso** | **No Defectuoso** | **Total** |
|---|---|---|---|
| **Marca 1** | **VP = 1,250** <br> *Verdaderos Positivos* | **VN = 3,750** <br> *Verdaderos Negativos* | **5,000** |
| **Otras Marcas** | **FP = 800** <br> *Falsos Positivos* | **FN = 4,200** <br> *Falsos Negativos* | **5,000** |
| **Total** | **2,050** | **7,950** | **10,000** |

### üéØ M√©tricas para Marca 1:

| **M√©trica** | **F√≥rmula** | **C√°lculo** | **Resultado** | **Interpretaci√≥n** |
|-------------|-------------|-------------|---------------|-------------------|
| **üéØ Valor Predictivo Positivo** <br> ***(ESTO ES BAYES)*** | **VP/(VP+FP)** | **1,250/(1,250+800)** | **61%** | **Si es defectuoso, ¬øqu√© % es marca 1?** |
| **Sensibilidad** <br> *(de Marca 1)* | VP/(VP+VN) | 1,250/(1,250+3,750) | **25%** | De marca 1, ¬øqu√© % es defectuoso? |
| **Especificidad** <br> *(para Marca 1)* | FN/(FN+FP) | 4,200/(4,200+800) | **84%** | De otras marcas, ¬øqu√© % no es defectuoso? |

**Interpretaci√≥n**: Si un televisor es defectuoso, hay **61%** de probabilidad de que sea marca 1.

**üîç Observaci√≥n clave**: Aunque marca 1 tiene solo 25% de defectuosos, al ser la marca m√°s vendida (50%), contribuye con m√°s defectuosos totales (1,250 de 2,050 = 61%).

## Ejemplo 2: Pruebas M√©dicas (Explicaci√≥n Detallada)

### Enunciado:
*"Una prueba m√©dica detecta correctamente una enfermedad en el 95% de los casos (sensibilidad). La probabilidad de falso positivo es 2% (especificidad = 98%). Si la enfermedad afecta al 1% de la poblaci√≥n, ¬øcu√°l es la probabilidad de tener la enfermedad si la prueba da positivo?"*

### An√°lisis Sem√°ntico:
- **"si la prueba da positivo"** ‚Üí Tenemos la evidencia
- **"¬øprobabilidad de tener la enfermedad?"** ‚Üí Buscamos la causa
- **Estructura cl√°sica de diagn√≥stico** ‚Üí **BAYES**

### Definici√≥n de Eventos:
- **E**: Tener la enfermedad
- **E^C**: NO tener la enfermedad (estar sano)
- **T+**: Prueba da resultado positivo
- **T-**: Prueba da resultado negativo

### Interpretaci√≥n de los Datos:
- **P(E) = 0.01** ‚Üí **Prevalencia**: Solo 1 de cada 100 personas tiene la enfermedad
- **P(E^C) = 0.99** ‚Üí **99 de cada 100 personas est√°n sanas**
- **P(T+|E) = 0.95** ‚Üí **Sensibilidad**: Si tienes la enfermedad, la prueba la detecta en 95% de los casos
- **P(T+|E^C) = 0.02** ‚Üí **Falso positivo**: Si est√°s sano, la prueba incorrectamente dice que est√°s enfermo en 2% de los casos

### Visualizaci√≥n con 10,000 Personas:

Imaginemos una poblaci√≥n de **10,000 personas**:

**üìä Distribuci√≥n de la Enfermedad:**
- **Enfermos**: 10,000 √ó 0.01 = **100 personas**
- **Sanos**: 10,000 √ó 0.99 = **9,900 personas**

**üî¨ Resultados de las Pruebas:**

**De las 100 personas ENFERMAS:**
- **Positivos correctos**: 100 √ó 0.95 = **95 personas** (verdaderos positivos)
- **Negativos incorrectos**: 100 √ó 0.05 = **5 personas** (falsos negativos)

**De las 9,900 personas SANAS:**
- **Positivos incorrectos**: 9,900 √ó 0.02 = **198 personas** (falsos positivos)
- **Negativos correctos**: 9,900 √ó 0.98 = **9,702 personas** (verdaderos negativos)

### Tabla de Resultados:

| Estado Real | Prueba + | Prueba - | Total |
|-------------|----------|----------|-------|
| **Enfermo** | 95       | 5        | 100   |
| **Sano**    | 198      | 9,702    | 9,900 |
| **Total**   | **293**  | 9,707    | 10,000|

### üìä Cuadro de M√©tricas Diagn√≥sticas

#### **Matriz de Confusi√≥n y Terminolog√≠a:**

| | **Prueba Positiva** | **Prueba Negativa** |
|---|---|---|
| **Realmente Enfermo** | **VP = 95** <br> *Verdaderos Positivos* | **FN = 5** <br> *Falsos Negativos* |
| **Realmente Sano** | **FP = 198** <br> *Falsos Positivos* | **VN = 9,702** <br> *Verdaderos Negativos* |

#### **M√©tricas Estad√≠sticas Importantes:**

| **M√©trica** | **F√≥rmula** | **C√°lculo** | **Resultado** | **Interpretaci√≥n** |
|-------------|-------------|-------------|---------------|-------------------|
| **Sensibilidad** <br> *(Recall, TPR)* | VP/(VP+FN) | 95/(95+5) | **95%** | De los enfermos, ¬øqu√© % detecta? |
| **Especificidad** <br> *(TNR)* | VN/(VN+FP) | 9,702/(9,702+198) | **98%** | De los sanos, ¬øqu√© % identifica correctamente? |
| **Valor Predictivo Positivo** <br> *(Precisi√≥n, PPV)* | VP/(VP+FP) | 95/(95+198) | **32.4%** | Si la prueba es +, ¬øqu√© % est√° realmente enfermo? |
| **Valor Predictivo Negativo** <br> *(NPV)* | VN/(VN+FN) | 9,702/(9,702+5) | **99.9%** | Si la prueba es -, ¬øqu√© % est√° realmente sano? |
| **Exactitud** <br> *(Accuracy)* | (VP+VN)/Total | (95+9,702)/10,000 | **97.97%** | ¬øQu√© % de diagn√≥sticos son correctos? |
| **Prevalencia** | (VP+FN)/Total | (95+5)/10,000 | **1%** | ¬øQu√© % de la poblaci√≥n tiene la enfermedad? |

#### **Interpretaci√≥n de cada m√©trica:**

**üéØ Sensibilidad (95%)**: *"Si tienes la enfermedad, la prueba la detectar√° en 95% de los casos"*
- **Alta sensibilidad** = Pocos falsos negativos
- **Importante cuando**: No queremos perder casos reales

**üéØ Especificidad (98%)**: *"Si est√°s sano, la prueba lo confirmar√° en 98% de los casos"*
- **Alta especificidad** = Pocos falsos positivos  
- **Importante cuando**: No queremos alarmar a personas sanas

**üéØ Valor Predictivo Positivo (32.4%)**: *"Si tu prueba es positiva, solo hay 32.4% de chance de que realmente tengas la enfermedad"*
- **ESTA ES LA RESPUESTA DE BAYES**
- Depende mucho de la prevalencia de la enfermedad

**üéØ Valor Predictivo Negativo (99.9%)**: *"Si tu prueba es negativa, hay 99.9% de chance de que realmente est√©s sano"*
- Muy alto porque la enfermedad es muy rara

**üéØ Exactitud/Accuracy (97.97%)**: *"La prueba da el diagn√≥stico correcto en casi 98% de los casos"*
- Puede ser enga√±osa en enfermedades raras
- Alta porque hay muchos verdaderos negativos

#### **üîç Observaciones Clave:**

1. **Paradoja de la Prevalencia**: Cuando una enfermedad es muy rara, incluso pruebas excelentes tienen bajo valor predictivo positivo

2. **Trade-off Sensibilidad vs Especificidad**: Generalmente, mejorar una empeora la otra

3. **Dependencia de la Prevalencia**: Los valores predictivos cambian seg√∫n qu√© tan com√∫n sea la enfermedad en la poblaci√≥n

4. **Accuracy puede enga√±ar**: En enfermedades muy raras, la accuracy puede ser alta simplemente porque la mayor√≠a est√° sana

### Soluci√≥n Paso a Paso:

**Paso 1: Calcular P(T+) - Total de pruebas positivas**
P(T+) = P(T+|E)√óP(E) + P(T+|E^C)√óP(E^C)
P(T+) = 0.95√ó0.01 + 0.02√ó0.99 = 0.0095 + 0.0198 = 0.0293

**En n√∫meros concretos**: 95 + 198 = **293 personas** tienen prueba positiva

**Paso 2: Aplicar Bayes**
P(E|T+) = [P(T+|E) √ó P(E)] / P(T+) = [0.95 √ó 0.01] / 0.0293 ‚âà 0.324

**En n√∫meros concretos**: De las 293 personas con prueba positiva, solo 95 est√°n realmente enfermas
**Probabilidad**: 95/293 = 0.324 = **32.4%**

### ¬øPor qu√© este resultado es tan contraintuitivo?

**üéØ La clave est√° en los n√∫meros absolutos:**

- **Verdaderos positivos**: 95 personas
- **Falsos positivos**: 198 personas
- **Total positivos**: 293 personas

**¬°Los falsos positivos (198) son el DOBLE que los verdaderos positivos (95)!**

### ¬øPor qu√© hay tantos falsos positivos?

1. **La enfermedad es MUY RARA** (solo 1%)
2. **Hay MUCHAS personas sanas** (99% = 9,900 personas)
3. **Incluso un peque√±o % de error** (2%) en 9,900 personas = 198 falsos positivos
4. **Los falsos positivos superan a los verdaderos positivos**

### Interpretaci√≥n Final:

**Si tu prueba sale positiva**, la probabilidad de que realmente tengas la enfermedad es solo **32.4%**.

**¬øEsto significa que la prueba es mala?** ¬°NO! La prueba es excelente:
- Detecta 95% de los casos reales
- Solo se equivoca 2% de las veces con personas sanas

**El problema es la BAJA PREVALENCIA** de la enfermedad.

### Lecci√≥n Importante:

Este ejemplo muestra por qu√© los m√©dicos a menudo piden **pruebas confirmatorias** cuando una primera prueba sale positiva, especialmente para enfermedades raras.

## Ejemplo 3: Control de Calidad

### Enunciado:
*"Una f√°brica tiene 3 m√°quinas: A produce 50% con 2% defectuosos, B produce 30% con 3% defectuosos, C produce 20% con 1% defectuosos. Si se encuentra un producto defectuoso, ¬øcu√°l es la probabilidad de que venga de la m√°quina B?"*

### An√°lisis Sem√°ntico:
- **"Si se encuentra un producto defectuoso"** ‚Üí Evidencia
- **"¬øprobabilidad de que venga de m√°quina B?"** ‚Üí Causa espec√≠fica
- **Patr√≥n de diagn√≥stico industrial** ‚Üí **BAYES**

### Soluci√≥n:

**Datos:**
- P(A) = 0.50, P(B) = 0.30, P(C) = 0.20
- P(D|A) = 0.02, P(D|B) = 0.03, P(D|C) = 0.01

**C√°lculo:**
P(D) = 0.02√ó0.50 + 0.03√ó0.30 + 0.01√ó0.20 = 0.01 + 0.009 + 0.002 = 0.021

P(B|D) = [P(D|B) √ó P(B)] / P(D) = [0.03 √ó 0.30] / 0.021 = 0.009 / 0.021 ‚âà 0.429

### Visualizaci√≥n con 10,000 Productos:

**üìä Distribuci√≥n por M√°quina:**
- **M√°quina A**: 10,000 √ó 0.50 = **5,000 productos**
- **M√°quina B**: 10,000 √ó 0.30 = **3,000 productos**
- **M√°quina C**: 10,000 √ó 0.20 = **2,000 productos**

**‚ö†Ô∏è Productos Defectuosos:**
- **M√°quina A defectuosos**: 5,000 √ó 0.02 = **100 productos**
- **M√°quina B defectuosos**: 3,000 √ó 0.03 = **90 productos**
- **M√°quina C defectuosos**: 2,000 √ó 0.01 = **20 productos**
- **Total defectuosos**: 100 + 90 + 20 = **210 productos**

### üìä Matriz de Confusi√≥n para M√°quina B:

| | **Defectuoso** | **No Defectuoso** | **Total** |
|---|---|---|---|
| **M√°quina B** | **VP = 90** <br> *Verdaderos Positivos* | **VN = 2,910** <br> *Verdaderos Negativos* | **3,000** |
| **Otras M√°quinas** | **FP = 120** <br> *Falsos Positivos* | **FN = 6,880** <br> *Falsos Negativos* | **7,000** |
| **Total** | **210** | **9,790** | **10,000** |

### üéØ M√©tricas para M√°quina B:

| **M√©trica** | **F√≥rmula** | **C√°lculo** | **Resultado** | **Interpretaci√≥n** |
|-------------|-------------|-------------|---------------|-------------------|
| **üéØ Valor Predictivo Positivo** <br> ***(ESTO ES BAYES)*** | **VP/(VP+FP)** | **90/(90+120)** | **42.9%** | **Si es defectuoso, ¬øqu√© % viene de m√°quina B?** |
| **Sensibilidad** <br> *(de M√°quina B)* | VP/(VP+VN) | 90/(90+2,910) | **3%** | De m√°quina B, ¬øqu√© % es defectuoso? |
| **Especificidad** <br> *(para M√°quina B)* | FN/(FN+FP) | 6,880/(6,880+120) | **98.3%** | De otras m√°quinas, ¬øqu√© % no es defectuoso? |

**Respuesta**: **42.9%** de probabilidad de que venga de la m√°quina B.

**üîç Observaci√≥n clave**: Aunque m√°quina B tiene la mayor tasa de defectos (3%), no produce la mayor√≠a de defectuosos porque produce menos volumen que m√°quina A.

## Ejemplo 4: An√°lisis de Email Spam

### Enunciado:
*"Un filtro de spam clasifica emails: 2% de emails son spam, 98% leg√≠timos. El filtro detecta correctamente 90% del spam y marca incorrectamente como spam el 1% de emails leg√≠timos. Si un email es marcado como spam, ¬øcu√°l es la probabilidad de que realmente sea spam?"*

### An√°lisis Sem√°ntico:
- **"Si un email es marcado como spam"** ‚Üí Evidencia del clasificador
- **"¬øprobabilidad de que realmente sea spam?"** ‚Üí Causa real
- **Problema de clasificaci√≥n** ‚Üí **BAYES**

### Soluci√≥n:

**Eventos:**
- S: Email es spam
- M: Email marcado como spam

**Datos:**
- P(S) = 0.02, P(S^C) = 0.98
- P(M|S) = 0.90, P(M|S^C) = 0.01

**C√°lculo:**
P(M) = 0.90√ó0.02 + 0.01√ó0.98 = 0.018 + 0.0098 = 0.0278

P(S|M) = [0.90 √ó 0.02] / 0.0278 = 0.018 / 0.0278 ‚âà 0.647

### Visualizaci√≥n con 10,000 Emails:

**üìß Distribuci√≥n Real:**
- **Spam real**: 10,000 √ó 0.02 = **200 emails**
- **Leg√≠timos reales**: 10,000 √ó 0.98 = **9,800 emails**

**üîç Lo que hace el Filtro:**

**De los 200 emails QUE SON SPAM:**
- **Marcados como spam**: 200 √ó 0.90 = **180 emails** (verdaderos positivos)
- **Marcados como leg√≠timos**: 200 √ó 0.10 = **20 emails** (falsos negativos)

**De los 9,800 emails QUE SON LEG√çTIMOS:**
- **Marcados como leg√≠timos**: 9,800 √ó 0.99 = **9,702 emails** (verdaderos negativos)
- **Marcados como spam**: 9,800 √ó 0.01 = **98 emails** (falsos positivos)

### üìä Matriz de Confusi√≥n para el Filtro de Spam:

| | **Marcado como SPAM** | **Marcado como LEG√çTIMO** | **Total** |
|---|---|---|---|
| **Realmente SPAM** | **VP = 180** <br> *Verdaderos Positivos* | **FN = 20** <br> *Falsos Negativos* | **200** |
| **Realmente LEG√çTIMO** | **FP = 98** <br> *Falsos Positivos* | **VN = 9,702** <br> *Verdaderos Negativos* | **9,800** |
| **Total** | **278** | **9,722** | **10,000** |

### üéØ M√©tricas del Filtro de Spam:

| **M√©trica** | **F√≥rmula** | **C√°lculo** | **Resultado** | **Interpretaci√≥n** |
|-------------|-------------|-------------|---------------|-------------------|
| **Sensibilidad** <br> *(Recall, TPR)* | VP/(VP+FN) | 180/(180+20) | **90%** | De los spam reales, ¬øqu√© % detecta? |
| **Especificidad** <br> *(TNR)* | VN/(VN+FP) | 9,702/(9,702+98) | **99%** | De los leg√≠timos, ¬øqu√© % identifica correctamente? |
| **üéØ Valor Predictivo Positivo** <br> ***(ESTO ES BAYES)*** | **VP/(VP+FP)** | **180/(180+98)** | **64.7%** | **Si es marcado como spam, ¬øqu√© % es realmente spam?** |
| **Valor Predictivo Negativo** <br> *(NPV)* | VN/(VN+FN) | 9,702/(9,702+20) | **99.8%** | Si es marcado como leg√≠timo, ¬øqu√© % es realmente leg√≠timo? |
| **Exactitud** <br> *(Accuracy)* | (VP+VN)/Total | (180+9,702)/10,000 | **98.82%** | ¬øQu√© % de clasificaciones son correctas? |

**Resultado**: **64.7%** de probabilidad de que sea realmente spam.

**üîç Observaci√≥n clave**: Aunque el filtro es muy bueno (90% sensibilidad, 99% especificidad), solo 64.7% de los emails marcados como spam son realmente spam, debido a la baja prevalencia del spam (2%).

## Pasos Sistem√°ticos para Resolver Problemas con Bayes

### 1. **Identificaci√≥n del Problema**
- ¬øTe dan el efecto y preguntan por la causa?
- ¬øHay estructura "Si [resultado], ¬øprobabilidad de [origen]?"

### 2. **Definir Eventos Claramente**
- Causa: A‚ÇÅ, A‚ÇÇ, A‚ÇÉ, ... (mutuamente excluyentes y exhaustivos)
- Efecto: B

### 3. **Recopilar Datos**
- P(A‚ÇÅ), P(A‚ÇÇ), P(A‚ÇÉ), ... (probabilidades a priori)
- P(B|A‚ÇÅ), P(B|A‚ÇÇ), P(B|A‚ÇÉ), ... (verosimilitudes)

### 4. **Calcular Probabilidad Total**
- P(B) = Œ£ P(B|A·µ¢) √ó P(A·µ¢)

### 5. **Aplicar Bayes**
- P(A·µ¢|B) = [P(B|A·µ¢) √ó P(A·µ¢)] / P(B)

### 6. **Interpretar en Contexto**
- ¬øQu√© significa el resultado en t√©rminos del problema original?

## Errores Comunes

### 1. **Confundir P(A|B) con P(B|A)**
- **Error**: Pensar que son iguales
- **Realidad**: Generalmente son muy diferentes

### 2. **Olvidar Calcular P(B)**
- **Error**: Intentar aplicar Bayes sin el denominador
- **Soluci√≥n**: Siempre calcular la probabilidad total primero

### 3. **No Considerar Todas las Causas**
- **Error**: Omitir causas posibles
- **Soluci√≥n**: Verificar que P(A‚ÇÅ) + P(A‚ÇÇ) + ... = 1

### 4. **Malinterpretar Prevalencia**
- **Error**: No considerar cu√°n rara es la condici√≥n
- **Soluci√≥n**: Prestar atenci√≥n especial a las probabilidades a priori

### 5. **Confundir Sensibilidad y Especificidad**
- **Sensibilidad**: P(Positivo|Enfermo)
- **Especificidad**: P(Negativo|Sano) = 1 - P(Positivo|Sano)

## Aplicaciones Pr√°cticas

### Diagn√≥stico M√©dico
- Interpretar resultados de pruebas
- Evaluar probabilidades de enfermedades

### Control de Calidad
- Identificar fuentes de defectos
- Optimizar procesos de producci√≥n

### Clasificaci√≥n y Filtrado
- Detecci√≥n de spam
- Reconocimiento de patrones

### Investigaci√≥n Criminal
- An√°lisis de evidencia
- Probabilidades de culpabilidad

## F√≥rmulas de Referencia

- **Teorema de Bayes**: P(A|B) = [P(B|A) √ó P(A)] / P(B)
- **Forma extendida**: P(A|B) = [P(B|A) √ó P(A)] / [Œ£ P(B|A·µ¢) √ó P(A·µ¢)]
- **Probabilidad total**: P(B) = Œ£ P(B|A·µ¢) √ó P(A·µ¢)
- **Odds posteriores**: P(A|B)/P(A^C|B) = [P(B|A)/P(B|A^C)] √ó [P(A)/P(A^C)]

---

*Recuerda: Bayes es la herramienta para "dar vuelta" la probabilidad condicional cuando necesitas ir del efecto a la causa.*
