# MigraciÃ³n a Estructura Centralizada de Datasets

## ðŸ“… Fecha: Octubre 2024

## ðŸŽ¯ Objetivo

Reorganizar los datasets del proyecto en una estructura centralizada para:
- Evitar duplicaciÃ³n de archivos
- Facilitar mantenimiento
- Mejorar la gestiÃ³n en Git
- Documentar mejor cada dataset

## âœ… Cambios Realizados

### 1. Estructura Creada

```
data/
â”œâ”€â”€ README.md                    # DocumentaciÃ³n principal
â”œâ”€â”€ dataset_loader.py           # Helper para cargar datasets
â”œâ”€â”€ shared/                     # Datasets compartidos
â”‚   â”œâ”€â”€ titanic/
â”‚   â”‚   â”œâ”€â”€ train.csv
â”‚   â”‚   â”œâ”€â”€ test.csv
â”‚   â”‚   â”œâ”€â”€ gender_submission.csv
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â”œâ”€â”€ financial/
â”‚   â”‚   â”œâ”€â”€ 2014-2018_Financial_Data.csv (5 archivos)
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â”œâ”€â”€ banking/
â”‚   â”‚   â”œâ”€â”€ bank.csv
â”‚   â”‚   â”œâ”€â”€ bank-full.csv
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â””â”€â”€ otros/
â”‚       â”œâ”€â”€ default of credit card clients.xls
â”‚       â””â”€â”€ README.md
â”œâ”€â”€ examples/                   # Para datasets pequeÃ±os < 1MB
â”‚   â””â”€â”€ .gitkeep
â””â”€â”€ U0/ ... U9/                # Datasets especÃ­ficos por unidad
    â””â”€â”€ .gitkeep
```

### 2. Datasets Migrados

#### Desde `practicas/practica0/` a `data/shared/`:
- âœ… 2014-2018_Financial_Data.csv â†’ financial/
- âœ… bank.csv, bank-full.csv â†’ banking/
- âœ… default of credit card clients.xls â†’ otros/
- âœ… test.csv, gender_submission.csv â†’ titanic/

#### Desde `0_Elementos_iniciales/` a `data/shared/`:
- âœ… train.csv â†’ titanic/

### 3. Archivos Actualizados

#### Notebooks
- âœ… `0_Elementos_iniciales/TGAD_Obtencion_de_datos_con_Python.ipynb`
  - bank.csv â†’ ../data/shared/banking/bank.csv
  - default of credit card clients.xls â†’ ../data/shared/otros/...
  - train.csv â†’ ../data/shared/titanic/train.csv

#### DocumentaciÃ³n
- âœ… `.gitignore` - Actualizado para excluir datos pero incluir READMEs
- âœ… `README.md` - Agregada secciÃ³n de datasets
- âœ… `data/README.md` - DocumentaciÃ³n completa de datasets
- âœ… `data/shared/*/README.md` - 4 READMEs especÃ­ficos creados
- âœ… `practicas/practica0/README.md` - Referencias a nueva ubicaciÃ³n

#### CÃ³digo
- âœ… `data/dataset_loader.py` - Helper para facilitar carga de datasets

### 4. ConfiguraciÃ³n Git

#### .gitignore actualizado:
```gitignore
# Excluir todos los datasets
*.csv
*.xlsx
*.xls

# EXCEPTO: datasets de ejemplo y READMEs
!data/examples/*.csv
!data/examples/*.xlsx
!example_data.csv
!data/**/README.md
!data/README.md
!data/**/.gitkeep
```

## ðŸ“Š Impacto

### Archivos Versionados (Solo estructura y docs):
- 16 archivos .gitkeep
- 6 archivos README.md
- 1 archivo dataset_loader.py
- **Total: ~15KB versionados**

### Archivos NO Versionados (Datos):
- 11 archivos de datos (CSV/XLS)
- **Total: ~50MB NO versionados**

## ðŸ”„ Compatibilidad

### Notebooks que DEBEN actualizarse:
- âœ… `0_Elementos_iniciales/TGAD_Obtencion_de_datos_con_Python.ipynb` - **YA ACTUALIZADO**

### Notebooks que NO requieren cambios:
- Notebooks que generan datos sintÃ©ticos
- Notebooks que usan APIs externas
- Notebooks sin datasets

## ðŸ“ Para Futuros Colaboradores

### Agregar un nuevo dataset:

1. **Colocar el archivo** en la ubicaciÃ³n apropiada:
   ```bash
   # Si es compartido
   cp mi_dataset.csv data/shared/[categoria]/
   
   # Si es especÃ­fico de una unidad
   cp mi_dataset.csv data/U5/
   ```

2. **Crear/actualizar README**:
   ```bash
   # Editar data/shared/[categoria]/README.md
   # Actualizar data/README.md
   ```

3. **Usar en notebooks**:
   ```python
   # OpciÃ³n 1: Usar el loader
   from dataset_loader import get_loader
   loader = get_loader()
   df = loader.load_custom('U5/mi_dataset.csv')
   
   # OpciÃ³n 2: Ruta directa
   df = pd.read_csv('../data/U5/mi_dataset.csv')
   ```

4. **Commitear** (solo docs, no datos):
   ```bash
   git add data/U5/.gitkeep data/shared/*/README.md
   git commit -m "Add documentation for new dataset"
   ```

## ðŸ” VerificaciÃ³n

### Verificar que la migraciÃ³n fue exitosa:

```bash
# 1. Verificar estructura
ls -la data/shared/

# 2. Verificar que datasets NO estÃ©n en staging
git status | grep -E "\.csv|\.xlsx|\.xls"
# Debe estar vacÃ­o o solo mostrar archivos en examples/

# 3. Verificar que READMEs SÃ estÃ©n en staging
git status | grep README.md
# Debe mostrar los READMEs

# 4. Probar carga de datos
python3 data/dataset_loader.py
```

## âš ï¸ Notas Importantes

1. **Los archivos originales se COPIARON, no se movieron**: Los datasets originales aÃºn estÃ¡n en `practicas/practica0/` y `0_Elementos_iniciales/`. Puedes eliminarlos despuÃ©s de verificar que todo funciona.

2. **Git no versionarÃ¡ los datasets grandes**: Esto es intencional para mantener el repositorio ligero.

3. **Paths de Google Colab**: Los notebooks que usan Google Colab (/content/, MyDrive/) NO fueron modificados ya que usan una estructura diferente.

## ðŸŽ“ Beneficios Obtenidos

âœ… OrganizaciÃ³n clara y escalable
âœ… DocumentaciÃ³n completa de cada dataset
âœ… Facilita colaboraciÃ³n (estructura vs datos)
âœ… Reduce tamaÃ±o del repositorio
âœ… Helper para carga consistente de datos
âœ… EnseÃ±a buenas prÃ¡cticas a estudiantes

---

*MigraciÃ³n completada: Octubre 2024*
